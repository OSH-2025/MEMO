# Qwen3-0.6B 本地部署微调版本（MVP版本）
由于本组的基于LLM预测用户行为的内存管理优化项目中，最需要高算力的部分便是模型微调模块，所以本组也针对该模块做了本地化、轻量级部署的尝试。
本模块使用 Qwen3-0.6B 模型作为训练对象。

## 目录结构
```
local_version/
 ├── data/                         # 存放训练/验证用的json数据文件
 ├── models/                       # 存放大模型参数文件
 ├── output/                       # 存放输出结果 
 ├── download.py                   # 下载大模型脚本
 ├── train.py                      # 大模型微调及准确度评估脚本
 ├── config.json                   # train.py 配置文件（包含路径信息和训练参数等信息）
 ├── README.md                     # 项目说明文档
 ├── requirements.txt              # 环境依赖文档
```

## 环境依赖

建议使用 Python 3.9+，推荐在虚拟环境下安装依赖。

请参考 `requirements.txt` 文件进行环境配置：

```bash
pip install -r requirements.txt
```

**主要依赖：**

- torch
- transformers
- datasets
- peft
- pandas
- numpy
- 及其它辅助库

## 快速开始

### 1. 下载大模型参数

```bash
python download.py
```

### 2. 准备训练数据

请将你的训练/验证数据（json文件）放入 `data/` 文件夹。

### 3. 微调模型

```bash
python train.py --config config.json
```

模型训练完成后，会自动保存预测结果到 `output/` 文件夹下。

## 结果展示

### 硬件与运行环境信息
本实验在以下设备与环境下完成微调训练：
* **操作系统**: Ubuntu 24.04.2 LTS (WSL2)
* **内核版本**: Linux 5.15.167.4-microsoft-standard-WSL2
* **Python 环境**: Python 3.9 + PyTorch

#### 计算资源
| 硬件组件        | 规格说明                               |
| ----------- | ---------------------------------- |
| **GPU**     | NVIDIA GeForce RTX 3080 Laptop GPU |
| **显存**      | 8GB GDDR6   |
| **CUDA 版本** | 12.8                               |
| **驱动版本**    | 572.83                             |

#### 系统资源
| 组件              | 规格说明                                            |
| --------------- | ----------------------------------------------- |
| **CPU**         | Intel 11th Gen Core i7-11800H @ 2.30GHz（8核16线程） |
| **内存**          | 7.6GB RAM                 |
| **交换空间 (Swap)** | 2.0GB                                |

### 训练样本 595, 验证样本 149

```r
完全匹配准确率: 0.1141 (17/149)
部分匹配准确率: 0.3423 (51/149)
不合规预测占比: 0.1007 (15/149)
总体准确率: 0.2852
```

### 训练样本 1022, 验证样本 256

```r
完全匹配准确率: 0.1719 (44/256)
部分匹配准确率: 0.3945 (101/256)
不合规预测占比: 0.1094 (28/256)
总体准确率: 0.3691
```

### 训练样本 2287, 验证样本 572

```r
完全匹配准确率: 0.1923 (110/572)
部分匹配准确率: 0.3776 (216/572)
不合规预测占比: 0.1503 (86/572)
总体准确率: 0.3811
```
随数据集大小的增长，用户行为预测准确率显著上升。由于该模块仅是出于对算力有限，普通用户的本地化微调可行性的考虑，我们并没有使用较大的LLM和大量的数据集来训练。在此只是做了可行性的验证，未来使用更大的数据集去训练，有理由认为模型预测准确率会进一步提升。
