output_dir,accuracy,partial_accuracy,overall_accuracy,hyper_params
output/exp1_lr0.0002_bs2_r8_a32,0.1453,0.3073,0.2989,"{'model_name_or_path': './LLM-Research/Meta-Llama-3___1-8B-Instruct', 'output_dir': 'output/exp1_lr0.0002_bs2_r8_a32', 'data_dir': 'data', 'max_length': 512, 'num_train_epochs': 3, 'learning_rate': 0.0002, 'per_device_train_batch_size': 2, 'per_device_eval_batch_size': 2, 'gradient_accumulation_steps': 4, 'logging_steps': 10, 'save_steps': 100, 'evaluation_strategy': 'epoch', 'save_strategy': 'epoch', 'load_best_model_at_end': False, 'metric_for_best_model': 'eval_loss', 'gradient_checkpointing': False, 'lora_r': 8, 'lora_alpha': 32, 'lora_dropout': 0.1, 'max_new_tokens': 100, 'temperature': 0.7, 'top_p': 0.9, 'train_frac': 0.8, 'seed': 42}"
output/exp2_lr0.0001_bs2_r8_a32,0.1229,0.3128,0.2793,"{'model_name_or_path': './LLM-Research/Meta-Llama-3___1-8B-Instruct', 'output_dir': 'output/exp2_lr0.0001_bs2_r8_a32', 'data_dir': 'data', 'max_length': 512, 'num_train_epochs': 3, 'learning_rate': 0.0001, 'per_device_train_batch_size': 2, 'per_device_eval_batch_size': 2, 'gradient_accumulation_steps': 4, 'logging_steps': 10, 'save_steps': 100, 'evaluation_strategy': 'epoch', 'save_strategy': 'epoch', 'load_best_model_at_end': False, 'metric_for_best_model': 'eval_loss', 'gradient_checkpointing': False, 'lora_r': 8, 'lora_alpha': 32, 'lora_dropout': 0.1, 'max_new_tokens': 100, 'temperature': 0.7, 'top_p': 0.9, 'train_frac': 0.8, 'seed': 42}"
output/exp3_lr0.0002_bs4_r8_a32,0.1564,0.2626,0.2877,"{'model_name_or_path': './LLM-Research/Meta-Llama-3___1-8B-Instruct', 'output_dir': 'output/exp3_lr0.0002_bs4_r8_a32', 'data_dir': 'data', 'max_length': 512, 'num_train_epochs': 3, 'learning_rate': 0.0002, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 4, 'gradient_accumulation_steps': 4, 'logging_steps': 10, 'save_steps': 100, 'evaluation_strategy': 'epoch', 'save_strategy': 'epoch', 'load_best_model_at_end': False, 'metric_for_best_model': 'eval_loss', 'gradient_checkpointing': False, 'lora_r': 8, 'lora_alpha': 32, 'lora_dropout': 0.1, 'max_new_tokens': 100, 'temperature': 0.7, 'top_p': 0.9, 'train_frac': 0.8, 'seed': 42}"
output/exp4_lr0.0002_bs2_r16_a64,0.1341,0.2737,0.2709,"{'model_name_or_path': './LLM-Research/Meta-Llama-3___1-8B-Instruct', 'output_dir': 'output/exp4_lr0.0002_bs2_r16_a64', 'data_dir': 'data', 'max_length': 512, 'num_train_epochs': 3, 'learning_rate': 0.0002, 'per_device_train_batch_size': 2, 'per_device_eval_batch_size': 2, 'gradient_accumulation_steps': 4, 'logging_steps': 10, 'save_steps': 100, 'evaluation_strategy': 'epoch', 'save_strategy': 'epoch', 'load_best_model_at_end': False, 'metric_for_best_model': 'eval_loss', 'gradient_checkpointing': False, 'lora_r': 16, 'lora_alpha': 64, 'lora_dropout': 0.1, 'max_new_tokens': 100, 'temperature': 0.7, 'top_p': 0.9, 'train_frac': 0.8, 'seed': 42}"
output/exp5_lr0.0005_bs2_r8_a32,0.1564,0.2849,0.2989,"{'model_name_or_path': './LLM-Research/Meta-Llama-3___1-8B-Instruct', 'output_dir': 'output/exp5_lr0.0005_bs2_r8_a32', 'data_dir': 'data', 'max_length': 512, 'num_train_epochs': 3, 'learning_rate': 0.0005, 'per_device_train_batch_size': 2, 'per_device_eval_batch_size': 2, 'gradient_accumulation_steps': 4, 'logging_steps': 10, 'save_steps': 100, 'evaluation_strategy': 'epoch', 'save_strategy': 'epoch', 'load_best_model_at_end': False, 'metric_for_best_model': 'eval_loss', 'gradient_checkpointing': False, 'lora_r': 8, 'lora_alpha': 32, 'lora_dropout': 0.1, 'max_new_tokens': 100, 'temperature': 0.7, 'top_p': 0.9, 'train_frac': 0.8, 'seed': 42}"
output/exp6_lr0.0001_bs4_r16_a64,0.1341,0.2905,0.2793,"{'model_name_or_path': './LLM-Research/Meta-Llama-3___1-8B-Instruct', 'output_dir': 'output/exp6_lr0.0001_bs4_r16_a64', 'data_dir': 'data', 'max_length': 512, 'num_train_epochs': 3, 'learning_rate': 0.0001, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 4, 'gradient_accumulation_steps': 4, 'logging_steps': 10, 'save_steps': 100, 'evaluation_strategy': 'epoch', 'save_strategy': 'epoch', 'load_best_model_at_end': False, 'metric_for_best_model': 'eval_loss', 'gradient_checkpointing': False, 'lora_r': 16, 'lora_alpha': 64, 'lora_dropout': 0.1, 'max_new_tokens': 100, 'temperature': 0.7, 'top_p': 0.9, 'train_frac': 0.8, 'seed': 42}"
output/exp7_lr0.0002_bs2_r8_a32_d0.2,0.1285,0.2849,0.2709,"{'model_name_or_path': './LLM-Research/Meta-Llama-3___1-8B-Instruct', 'output_dir': 'output/exp7_lr0.0002_bs2_r8_a32_d0.2', 'data_dir': 'data', 'max_length': 512, 'num_train_epochs': 3, 'learning_rate': 0.0002, 'per_device_train_batch_size': 2, 'per_device_eval_batch_size': 2, 'gradient_accumulation_steps': 4, 'logging_steps': 10, 'save_steps': 100, 'evaluation_strategy': 'epoch', 'save_strategy': 'epoch', 'load_best_model_at_end': False, 'metric_for_best_model': 'eval_loss', 'gradient_checkpointing': False, 'lora_r': 8, 'lora_alpha': 32, 'lora_dropout': 0.2, 'max_new_tokens': 100, 'temperature': 0.7, 'top_p': 0.9, 'train_frac': 0.8, 'seed': 42}"
output/exp8_lr0.0002_bs1_r8_a32_gs8,0.1620,0.2626,0.2933,"{'model_name_or_path': './LLM-Research/Meta-Llama-3___1-8B-Instruct', 'output_dir': 'output/exp8_lr0.0002_bs1_r8_a32_gs8', 'data_dir': 'data', 'max_length': 512, 'num_train_epochs': 3, 'learning_rate': 0.0002, 'per_device_train_batch_size': 1, 'per_device_eval_batch_size': 1, 'gradient_accumulation_steps': 8, 'logging_steps': 10, 'save_steps': 100, 'evaluation_strategy': 'epoch', 'save_strategy': 'epoch', 'load_best_model_at_end': False, 'metric_for_best_model': 'eval_loss', 'gradient_checkpointing': False, 'lora_r': 8, 'lora_alpha': 32, 'lora_dropout': 0.1, 'max_new_tokens': 100, 'temperature': 0.7, 'top_p': 0.9, 'train_frac': 0.8, 'seed': 42}"
output/exp9_lr0.00005_bs2_r8_a32,0.1453,0.2737,0.2821,"{'model_name_or_path': './LLM-Research/Meta-Llama-3___1-8B-Instruct', 'output_dir': 'output/exp9_lr0.00005_bs2_r8_a32', 'data_dir': 'data', 'max_length': 512, 'num_train_epochs': 3, 'learning_rate': 5e-05, 'per_device_train_batch_size': 2, 'per_device_eval_batch_size': 2, 'gradient_accumulation_steps': 4, 'logging_steps': 10, 'save_steps': 100, 'evaluation_strategy': 'epoch', 'save_strategy': 'epoch', 'load_best_model_at_end': False, 'metric_for_best_model': 'eval_loss', 'gradient_checkpointing': False, 'lora_r': 8, 'lora_alpha': 32, 'lora_dropout': 0.1, 'max_new_tokens': 100, 'temperature': 0.7, 'top_p': 0.9, 'train_frac': 0.8, 'seed': 42}"
output/exp10_lr0.0001_bs2_r32_a128,0.1508,0.2961,0.2989,"{'model_name_or_path': './LLM-Research/Meta-Llama-3___1-8B-Instruct', 'output_dir': 'output/exp10_lr0.0001_bs2_r32_a128', 'data_dir': 'data', 'max_length': 512, 'num_train_epochs': 3, 'learning_rate': 0.0001, 'per_device_train_batch_size': 2, 'per_device_eval_batch_size': 2, 'gradient_accumulation_steps': 4, 'logging_steps': 10, 'save_steps': 100, 'evaluation_strategy': 'epoch', 'save_strategy': 'epoch', 'load_best_model_at_end': False, 'metric_for_best_model': 'eval_loss', 'gradient_checkpointing': False, 'lora_r': 32, 'lora_alpha': 128, 'lora_dropout': 0.1, 'max_new_tokens': 100, 'temperature': 0.7, 'top_p': 0.9, 'train_frac': 0.8, 'seed': 42}"
output/exp11_lr0.001_bs2_r8_a32,0.1676,0.2849,0.3101,"{'model_name_or_path': './LLM-Research/Meta-Llama-3___1-8B-Instruct', 'output_dir': 'output/exp11_lr0.001_bs2_r8_a32', 'data_dir': 'data', 'max_length': 512, 'num_train_epochs': 3, 'learning_rate': 0.001, 'per_device_train_batch_size': 2, 'per_device_eval_batch_size': 2, 'gradient_accumulation_steps': 4, 'logging_steps': 10, 'save_steps': 100, 'evaluation_strategy': 'epoch', 'save_strategy': 'epoch', 'load_best_model_at_end': False, 'metric_for_best_model': 'eval_loss', 'gradient_checkpointing': False, 'lora_r': 8, 'lora_alpha': 32, 'lora_dropout': 0.1, 'max_new_tokens': 100, 'temperature': 0.7, 'top_p': 0.9, 'train_frac': 0.8, 'seed': 42}"
output/exp12_lr0.0005_bs2_r32_a128,0.1397,0.2737,0.2765,"{'model_name_or_path': './LLM-Research/Meta-Llama-3___1-8B-Instruct', 'output_dir': 'output/exp12_lr0.0005_bs2_r32_a128', 'data_dir': 'data', 'max_length': 512, 'num_train_epochs': 3, 'learning_rate': 0.0005, 'per_device_train_batch_size': 2, 'per_device_eval_batch_size': 2, 'gradient_accumulation_steps': 4, 'logging_steps': 10, 'save_steps': 100, 'evaluation_strategy': 'epoch', 'save_strategy': 'epoch', 'load_best_model_at_end': False, 'metric_for_best_model': 'eval_loss', 'gradient_checkpointing': False, 'lora_r': 32, 'lora_alpha': 128, 'lora_dropout': 0.1, 'max_new_tokens': 100, 'temperature': 0.7, 'top_p': 0.9, 'train_frac': 0.8, 'seed': 42}"
output/exp13_lr0.0002_bs2_r64_a256,0.1620,0.2737,0.2989,"{'model_name_or_path': './LLM-Research/Meta-Llama-3___1-8B-Instruct', 'output_dir': 'output/exp13_lr0.0002_bs2_r64_a256', 'data_dir': 'data', 'max_length': 512, 'num_train_epochs': 3, 'learning_rate': 0.0002, 'per_device_train_batch_size': 2, 'per_device_eval_batch_size': 2, 'gradient_accumulation_steps': 4, 'logging_steps': 10, 'save_steps': 100, 'evaluation_strategy': 'epoch', 'save_strategy': 'epoch', 'load_best_model_at_end': False, 'metric_for_best_model': 'eval_loss', 'gradient_checkpointing': False, 'lora_r': 64, 'lora_alpha': 256, 'lora_dropout': 0.1, 'max_new_tokens': 100, 'temperature': 0.7, 'top_p': 0.9, 'train_frac': 0.8, 'seed': 42}"
output/exp14_lr0.0002_bs2_r8_a32_ep5,0.1508,0.3128,0.3073,"{'model_name_or_path': './LLM-Research/Meta-Llama-3___1-8B-Instruct', 'output_dir': 'output/exp14_lr0.0002_bs2_r8_a32_ep5', 'data_dir': 'data', 'max_length': 512, 'num_train_epochs': 5, 'learning_rate': 0.0002, 'per_device_train_batch_size': 2, 'per_device_eval_batch_size': 2, 'gradient_accumulation_steps': 4, 'logging_steps': 10, 'save_steps': 100, 'evaluation_strategy': 'epoch', 'save_strategy': 'epoch', 'load_best_model_at_end': False, 'metric_for_best_model': 'eval_loss', 'gradient_checkpointing': False, 'lora_r': 8, 'lora_alpha': 32, 'lora_dropout': 0.1, 'max_new_tokens': 100, 'temperature': 0.7, 'top_p': 0.9, 'train_frac': 0.8, 'seed': 42}"
output/exp15_lr0.0002_bs2_r8_a32_ml768_gc,0.1564,0.2961,0.3045,"{'model_name_or_path': './LLM-Research/Meta-Llama-3___1-8B-Instruct', 'output_dir': 'output/exp15_lr0.0002_bs2_r8_a32_ml768_gc', 'data_dir': 'data', 'max_length': 768, 'num_train_epochs': 3, 'learning_rate': 0.0002, 'per_device_train_batch_size': 2, 'per_device_eval_batch_size': 2, 'gradient_accumulation_steps': 4, 'logging_steps': 10, 'save_steps': 100, 'evaluation_strategy': 'epoch', 'save_strategy': 'epoch', 'load_best_model_at_end': False, 'metric_for_best_model': 'eval_loss', 'gradient_checkpointing': True, 'lora_r': 8, 'lora_alpha': 32, 'lora_dropout': 0.1, 'max_new_tokens': 100, 'temperature': 0.7, 'top_p': 0.9, 'train_frac': 0.8, 'seed': 42}"
output/exp16_lr0.0003_bs2_r32_a128_ep4_d0.05,0.1732,0.2793,0.3128,"{'model_name_or_path': './LLM-Research/Meta-Llama-3___1-8B-Instruct', 'output_dir': 'output/exp16_lr0.0003_bs2_r32_a128_ep4_d0.05', 'data_dir': 'data', 'max_length': 512, 'num_train_epochs': 4, 'learning_rate': 0.0003, 'per_device_train_batch_size': 2, 'per_device_eval_batch_size': 2, 'gradient_accumulation_steps': 4, 'logging_steps': 10, 'save_steps': 100, 'evaluation_strategy': 'epoch', 'save_strategy': 'epoch', 'load_best_model_at_end': False, 'metric_for_best_model': 'eval_loss', 'gradient_checkpointing': False, 'lora_r': 32, 'lora_alpha': 128, 'lora_dropout': 0.05, 'max_new_tokens': 100, 'temperature': 0.7, 'top_p': 0.9, 'train_frac': 0.8, 'seed': 42}"
output/exp18_lr0.0003_bs2_r64_a256_ep4_d0.05,0.1508,0.3128,0.3073,"{'model_name_or_path': './LLM-Research/Meta-Llama-3___1-8B-Instruct', 'output_dir': 'output/exp18_lr0.0003_bs2_r64_a256_ep4_d0.05', 'data_dir': 'data', 'max_length': 512, 'num_train_epochs': 4, 'learning_rate': 0.0003, 'per_device_train_batch_size': 2, 'per_device_eval_batch_size': 2, 'gradient_accumulation_steps': 4, 'logging_steps': 10, 'save_steps': 100, 'evaluation_strategy': 'epoch', 'save_strategy': 'epoch', 'load_best_model_at_end': False, 'metric_for_best_model': 'eval_loss', 'gradient_checkpointing': False, 'lora_r': 64, 'lora_alpha': 256, 'lora_dropout': 0.05, 'max_new_tokens': 100, 'temperature': 0.7, 'top_p': 0.9, 'train_frac': 0.8, 'seed': 42}"
output/exp19_lr0.0015_bs2_r32_a128_ep4_d0.05,0.0000,0.0000,0.0000,"{'model_name_or_path': './LLM-Research/Meta-Llama-3___1-8B-Instruct', 'output_dir': 'output/exp19_lr0.0015_bs2_r32_a128_ep4_d0.05', 'data_dir': 'data', 'max_length': 512, 'num_train_epochs': 4, 'learning_rate': 0.0015, 'per_device_train_batch_size': 2, 'per_device_eval_batch_size': 2, 'gradient_accumulation_steps': 4, 'logging_steps': 10, 'save_steps': 100, 'evaluation_strategy': 'epoch', 'save_strategy': 'epoch', 'load_best_model_at_end': False, 'metric_for_best_model': 'eval_loss', 'gradient_checkpointing': False, 'lora_r': 32, 'lora_alpha': 128, 'lora_dropout': 0.05, 'max_new_tokens': 100, 'temperature': 0.7, 'top_p': 0.9, 'train_frac': 0.8, 'seed': 42}"
output/exp20_lr0.0003_bs2_r32_a128_ep4_d0.05_ml768,0.1508,0.2793,0.2905,"{'model_name_or_path': './LLM-Research/Meta-Llama-3___1-8B-Instruct', 'output_dir': 'output/exp20_lr0.0003_bs2_r32_a128_ep4_d0.05_ml768', 'data_dir': 'data', 'max_length': 768, 'num_train_epochs': 4, 'learning_rate': 0.0003, 'per_device_train_batch_size': 2, 'per_device_eval_batch_size': 2, 'gradient_accumulation_steps': 4, 'logging_steps': 10, 'save_steps': 100, 'evaluation_strategy': 'epoch', 'save_strategy': 'epoch', 'load_best_model_at_end': False, 'metric_for_best_model': 'eval_loss', 'gradient_checkpointing': True, 'lora_r': 32, 'lora_alpha': 128, 'lora_dropout': 0.05, 'max_new_tokens': 100, 'temperature': 0.7, 'top_p': 0.9, 'train_frac': 0.8, 'seed': 42}"
output/exp_optimal_lr0.0003_bs2_r32,0.1676,0.2737,0.3045,"{'model_name_or_path': './LLM-Research/Meta-Llama-3___1-8B-Instruct', 'output_dir': 'output/exp_optimal_lr0.0003_bs2_r32', 'data_dir': 'data', 'max_length': 512, 'num_train_epochs': 4, 'learning_rate': 0.0003, 'per_device_train_batch_size': 2, 'per_device_eval_batch_size': 2, 'gradient_accumulation_steps': 4, 'logging_steps': 10, 'save_steps': 100, 'evaluation_strategy': 'epoch', 'save_strategy': 'epoch', 'load_best_model_at_end': False, 'metric_for_best_model': 'eval_loss', 'gradient_checkpointing': False, 'lora_r': 32, 'lora_alpha': 128, 'lora_dropout': 0.05, 'max_new_tokens': 100, 'temperature': 0.7, 'top_p': 0.9, 'train_frac': 0.8, 'seed': 42}"
