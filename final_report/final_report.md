# 结题报告

## 小组成员
* 于宛扬（组长）
* 杨玺禾
* 韩思琦
* 贾钰珩

## 引言

### 项目背景
随着人工智能技术的快速发展，尤其是大语言模型（如LLaMA、Qwen、GPT 等）在自然语言处理、上下文建模、意图理解等方面的突破，人机交互系统正逐步从“被动响应”向“主动预测”演进。传统的应用程序或操作系统仅在用户发出明确指令后执行操作，而随着用户对效率和智能化的期待不断提高，能够预判用户需求并提前执行操作的系统显得尤为重要。

本项目的核心目标是：利用大模型对用户的历史操作行为进行学习，从而预测其未来的操作，并进行智能反馈或预执行操作，从而优化用户体验和交互效率。

#### 一、技术背景

##### 1.用户行为建模的逐步成熟
在移动应用、操作系统和网页行为分析等领域，用户行为数据早已被广泛用于分析使用偏好和优化界面设计。然而传统方法多依赖于统计模型或浅层机器学习算法，难以捕捉长程依赖和复杂语义关系。而大模型特别是因上下文感知能力强、对多模态输入具备适配性的优势，已成为建模用户序列数据的理想选择。

##### 2.大模型 + LoRA 微调的有效融合
大模型虽强，但部署成本高，训练门槛高。Low-Rank Adaptation (LoRA) 提供了一种轻量级、低资源开销的参数微调方式，使得我们能够在保留大模型泛化能力的同时，专注于用户特定数据的学习，这对于个性化预测尤其重要。

##### 3.系统层集成与自动化反馈的趋势
随着本地大模型部署工具（如 llama.cpp、vLLM）与操作系统接口（如 Windows API、macOS Automation）的打通，未来可以实现“预测即响应”的闭环操作体验，例如在你即将打开某网页或文件前，系统就已预加载内容甚至提前打开目标应用。

#### 二、已有商业案例对比参考
* Google Now / Google Assistant：通过分析用户日程、搜索、位置数据提供“预测性卡片”，但模型粒度不够个性化，无法基于本地应用行为细粒度预测。
* Apple Siri Suggestions：能基于近期 App 使用习惯进行建议，但其模型为黑盒，无法在本地个性化训练或嵌入微调机制。

相比之下，本项目的优势在于：
* 使用LoRA 微调后的大语言模型，具备更强上下文理解与泛化能力；
* 基于真实用户的时间操作序列数据进行建模，更具个性化；
* 可集成到本地系统中形成完整闭环，实现预测—执行一体化。
### 项目成果概述



## 项目总体架构
![architecture](/final_report/asset/architecture.png)


## 各模块技术细节

### 数据收集



### LLM微调

#### 大模型微调背景
大规模预训练语言模型（如 LLaMA、Qwen、GPT 等）通常具备强大的泛化能力，但它们的参数规模巨大（通常数亿至数千亿参数），训练和更新成本高昂。直接对整个大模型进行微调：
* 需要大量计算资源和显存，
* 容易导致“灾难性遗忘”，使模型丧失原有通用知识，
* 微调后的模型体积庞大，部署困难。

因此，在实际应用中，往往采用更高效的微调技术，使模型能针对特定任务或领域快速适应，同时保留原模型权重不变。

#### LoRA（Low-Rank Adaptation）技术原理
LoRA 是一种近年来提出的轻量级微调方法，主要思想是在保持预训练模型主权重不变的基础上，仅学习一小部分低秩矩阵参数，以调整模型的表达能力。

具体原理如下：
* 对 Transformer 中的权重矩阵 $W_0\in \mathbb{R}^{m\times n}$ （例如查询、键、值矩阵）进行微调时，不直接更新 $W_0$ ，而是用两个低秩矩阵 $A\in \mathbb{R}^{m\times r}$， $B\in \mathbb{R}^{r\times m}$ 来近似微调参数增量，
* 微调后的权重表示为：
 $W_1=W_0+\Delta W=W_0+A\cdot B$
其中 $r\ll\mathrm{min}\{m,n\}$ ，即秩远小于矩阵维度，显著减少需要训练的参数量。
* 训练时只更新 $A$ 和 $B$ ，主权重 $W_0$保持冻结。

#### LoRA 的优点
* 参数量少，训练效率高

  只需训练低秩矩阵，参数量减少数百倍以上，显著节省显存和计算资源。
* 避免灾难性遗忘

  主模型权重保持不变，微调时保留原有知识，增强泛化能力。
* 易于集成和部署

  微调参数是增量权重，可以方便地与原始模型融合或分开存储，实现模块化更新。
* 适合个性化和增量训练

  对不同用户或任务可训练独立的低秩矩阵，支持模型快速适配。

#### LoRA 在本模块中的具体应用

### 预测调度



### 实时调度



## 实验结果



## 总结

### 项目成果回顾

### 未来工作展望

## References

1. Ravenscraft, Eric (2012-10-29). "Google Search Updated, Brings New Google Now Cards And Voice Actions - Yes, You Can Set Calendar Events". Android Police. Retrieved 2012-10-31. https://www.androidpolice.com/2012/10/29/google-search-updated-brings-new-google-now-cards-and-voice-actions-yes-you-can-set-calendar-events/
2. Gartenberg, Chaim (June 5, 2017). "Siri on iOS 11 gets improved speech and can suggest actions based on how you use it". The Verge. Vox Media. Retrieved June 10, 2017. https://www.theverge.com/2017/6/5/15732136/apple-siri-update-announced-new-features-wwdc-2017
3. 